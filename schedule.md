---
layout: default
---

&nbsp;


| # | Date  | Topic  | Notes | Lecture | Notebook  |
|-|-|-|-|-|-|
| | | **Part I: Basic gradient methods** | | | |
| 1 | 08.(23/25) | Intro & Preliminaries  | [.pdf](/schedule/images/chapter1.pdf) | [.pdf](/schedule/images/Lecture 1.pdf) | [.ipynb](/schedule/images/Chapter 1a.ipynb) [.ipynb](/schedule/images/Chapter 1b.ipynb)
| 2 | 08.30-09.(01/06) | Gradient method | [.pdf](/schedule/images/chapter2.pdf)  | [.pdf](/schedule/images/Lecture 2.pdf) | [.ipynb](/schedule/images/Chapter 2.ipynb) |
| 3 | 09.(08/13) | Gradient method & Convexity | [.pdf](/schedule/images/chapter3.pdf)  | [.pdf](/schedule/images/Lecture 3.pdf) | [.ipynb](/schedule/images/Chapter 3.ipynb) |
| 4 | 09.(15/20)  | Conditional gradient (Frank-Wolfe) | [.pdf]()  | [.pdf]() | [.ipynb]() |
| | | **Part II: Going faster than basic gradient descent** | | | |
| 5 | 09.(22/27) | Beyond first-order methods | [.pdf]()  | [.pdf]() | [.ipynb]() |
| 6 | 09.29-10.04) | Momemtum acceleration | [.pdf]()  | [.pdf]() | [.ipynb]() |
| 7 | 10.(06/13) | Stochastic motions in gradient descent | [.pdf]()  | [.pdf]() | [.ipynb]() |
| | | **Part III: Provable non-convex optimization** | | | |
| 8 | 10.(18/20/25) | Sparse feature selection and recovery | [.pdf]() / [.pdf]() | [.pdf]() | [.ipynb]() |
|  |  | | (Handwritten / Latex) |  | |
| 9 | 10.27-11.01 | Low-rank recovery | [.pdf]() / [.pdf]() | [.pdf]() | [.ipynb]() |
|  |  | | (Handwritten / Latex) |  | |
| | | **Part IV: Optimization methods in modern ML** | | | |
| 10 | 11.(03/08) | Landscape properties of general functions |  [.pdf]()  | [.pdf]() | --- |
| 11 | 11.(10/15) | Algorithms for NN training | [.pdf]() | [.pdf]() | --- |
| 12 | 11.(17/22) | To be decided | [.pdf]() | [.pdf]() | --- |
| 13 | 11.29-12.01 | Project presentations  | ---  | ---  | --- |
| | | **Part V: Final exam** | | | |

&nbsp;
&nbsp;
