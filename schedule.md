---
layout: default
---

&nbsp;


| # | Date  | Topic  | Notes | Lecture | Notebook  |
|-|-|-|-|-|-|
| | | **Part I: Basic gradient methods** | | | |
| 1 | 08/30 | Intro & Preliminaries  | [.pdf](/schedule/images/chapter1.pdf) | [.pdf](/schedule/images/Lecture 1.pdf) | [.ipynb](/schedule/images/Chapter 1a.ipynb) [.ipynb](/schedule/images/Chapter 1b.ipynb)
| - | 09/06 | *No class (traveling)* | ---  | ---  | --- |
| 2 | 09/13 | Gradient method | [.pdf](/schedule/images/chapter2.pdf)  | [.pdf](/schedule/images/Lecture 2.pdf) | [.ipynb](/schedule/images/Chapter 2.ipynb) |
| - | 09/20 | *No class (Imelda)* | ---  | --- | --- |
| 3 | 09/27 | Gradient method & Convexity | [.pdf]()  | --- | --- |
| 4 | 10/04 | Conditional gradient (Frank-Wolfe) | [.pdf]()  | [.ipynb]()  | --- |
| | | **Part II: Going faster than basic gradient descent** | | | |
| 5 | 10/11 | Beyond first-order methods | [.pdf]()  | [.ipynb]()  | --- |
| - | 10/18 | *No class (Traveling)* | ---  | ---  | --- |
| 6 | 10/25 | Momemtum acceleration | [.pdf]()  | [.ipynb]()  | --- |
| 7 | 11/01 | Stochastic motions in gradient descent | [.pdf]()  | [.ipynb]()  | --- |
| | | **Part III: Provable non-convex optimization** | | | |
| 8 | 11/08 | Sparse feature selection and recovery | [.pdf]()  | [.ipynb]()  | --- |
| 9 | 11/15 | Low-rank recovery | [.pdf]()  | [.ipynb]()  | --- |
| 10 | 11/22 | Alternating minimization and the EM algorithm | [.pdf]()  | [.ipynb]()  | --- |
| - | 11/29 | *No class (Thanksgiving - have fun!)* | ---  | ---  | --- |
| 11 | 12/06 | Landscape properties of general functions | [.pdf]()  | [.ipynb]()  | --- |
| | | **Part IV: Optimization methods in modern ML** | | | |
| 12 | 12/06 | Methods for training NNs  | [.pdf]()  | [.ipynb]()  | --- |
| 13 | 12/06 | Methods that scale up and out | [.pdf]()  | [.ipynb]()  | --- |

