{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuclear norm minimization vs. IHT for low-rank matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import random\n",
    "from numpy import linalg as la\n",
    "\n",
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "p = 128  # Matrices of size p x p\n",
    "r = 2   # low rank level\n",
    "n = np.ceil(5 * p * r)\n",
    "\n",
    "# Generate a pxp-dimensional zero matrix\n",
    "A = np.random.randn(p, r)\n",
    "B = np.random.randn(p, r)\n",
    "X_star = A.dot(B.T)\n",
    "X_star = (1 / la.norm(X_star, 'fro')) * X_star\n",
    "\n",
    "# Generate matrices for the sensing mechanism\n",
    "A = np.zeros((int(n), p, p))\n",
    "for i in range(int(n)):\n",
    "    C = (1/np.sqrt(n)) * np.random.randn(p, p)\n",
    "    A[i, :, :] = C\n",
    "\n",
    "# print(A[1, :, :])\n",
    "# print(np.squeeze(A[i, :, :]))\n",
    "# print(np.squeeze(A[i, :, :]).shape)\n",
    "# print(1/np.sqrt(n))\n",
    "# Observation model\n",
    "y = np.zeros(int(n))\n",
    "\n",
    "for i in range(int(n)):\n",
    "    B = np.squeeze(A[i, :, :])\n",
    "    y[i] = np.trace(B.dot(X_star.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds, eigs\n",
    "\n",
    "# Hard thresholding function\n",
    "def hardThreshold(X, r):\n",
    "    U, S, V = svds(X, k = r)    \n",
    "    S = np.diag(S)\n",
    "    return U.dot(S.dot(V))\n",
    "\n",
    "def l1normProj(x, l):\n",
    "    assert l > 0, \"Radius lambda must be strictly positive (%d <= 0)\" % l\n",
    "    n, = x.shape  \n",
    "    \n",
    "    u = np.abs(x)                               # compute the vector of absolute values\n",
    "    \n",
    "    if u.sum() <= l:                            # check if v is already a solution    \n",
    "        return x\n",
    "    \n",
    "    u = np.sort(x)[::-1]                        # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    cssv = np.cumsum(u)\n",
    "    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - l))[0][-1]   # get the number of > 0 components of the optimal solution\n",
    "    theta = (float(cssv[rho] - l) / rho).clip(min=0)                 # compute the projection by thresholding v using theta          # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    w = (np.abs(x) - theta).clip(min=0)                 # compute the projection by thresholding v using theta\n",
    "    w *= np.sign(x)    \n",
    "        \n",
    "    return w\n",
    "\n",
    "def proj_nuclear_norm(X, l):\n",
    "    U, S, V = la.svd(X)\n",
    "    S = l1normProj(S, l)\n",
    "    S = np.diag(S)\n",
    "    return U.dot(S.dot(V))\n",
    "    \n",
    "# Returns the value of the objecive function\n",
    "def f(y, A, X):\n",
    "    f_value = 0\n",
    "    n = y.shape[0]\n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])\n",
    "        f_value += 0.5 * (y[i] - np.trace(B.dot(X.T)))**2\n",
    "    return f_value\n",
    "\n",
    "def compute_grad(y, A, X):\n",
    "    n = y.shape[0]\n",
    "    p = A.shape[1]\n",
    "\n",
    "    grad = np.zeros((p, p))\n",
    "    b = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])        \n",
    "        b[i] = y[i] - np.trace(B.dot(X.T))\n",
    "    \n",
    "#     print(b)\n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])\n",
    "        grad += -b[i] * B;\n",
    "    \n",
    "#     print(grad)\n",
    "    return grad\n",
    "\n",
    "def matrix_IHT(y, A, r, eta, iters, epsilon, verbose, X_star):\n",
    "    # Length of original signal\n",
    "    p = A.shape[1]\n",
    "    # Length of measurement vector\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initial estimate\n",
    "    X_new = np.zeros((p, p))\n",
    "    \n",
    "    X_list, f_list = [1], [f(y, A, X_new)]\n",
    "\n",
    "    for i in range(iters):\n",
    "        X_old = X_new\n",
    "    \n",
    "        # Compute gradient\n",
    "        grad = compute_grad(y, A, X_old)\n",
    "#         print(grad)\n",
    "        # Perform gradient step\n",
    "        X_temp = X_old - eta * grad    \n",
    "    \n",
    "        # Perform hard thresholding step\n",
    "        X_new = hardThreshold(X_temp, r)\n",
    "    \n",
    "        if (la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')) < epsilon:\n",
    "            break\n",
    "                \n",
    "        # Keep track of solutions and objective values\n",
    "        X_list.append(la.norm(X_new - X_star, 'fro'))\n",
    "        f_list.append(f(y, A, X_new))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"iter# = \"+ str(i) + \", ||X_new - X_old||_2 = \" + str(la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')))\n",
    "    \n",
    "    print(\"Number of steps:\", len(f_list))\n",
    "    return X_new, X_list, f_list\n",
    "\n",
    "def matrix_nuclear_norm_min(y, A, l, eta, iters, epsilon, verbose, X_star):\n",
    "    # Length of original signal\n",
    "    p = A.shape[1]\n",
    "    # Length of measurement vector\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initial estimate\n",
    "    X_new = np.zeros((p, p))\n",
    "    \n",
    "    X_list, f_list = [1], [f(y, A, X_new)]\n",
    "\n",
    "    for i in range(iters):\n",
    "        X_old = X_new\n",
    "    \n",
    "        # Compute gradient\n",
    "        grad = compute_grad(y, A, X_old)\n",
    "    \n",
    "        # Perform gradient step\n",
    "        X_temp = X_old - eta * grad    \n",
    "    \n",
    "        # Perform hard thresholding step\n",
    "        X_new = proj_nuclear_norm(X_temp, l)\n",
    "    \n",
    "        if (la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')) < epsilon:\n",
    "            break\n",
    "                \n",
    "        # Keep track of solutions and objective values\n",
    "        X_list.append(la.norm(X_new - X_star, 'fro'))\n",
    "        f_list.append(f(y, A, X_new))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"iter# = \"+ str(i) + \", ||X_new - X_old||_2 = \" + str(la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')))\n",
    "    \n",
    "    print(\"Number of steps:\", len(f_list))\n",
    "    return X_new, X_list, f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 0, ||X_new - X_old||_2 = 1.0\n",
      "iter# = 1, ||X_new - X_old||_2 = 0.4539310614839091\n",
      "iter# = 2, ||X_new - X_old||_2 = 0.27632978515380846\n",
      "iter# = 3, ||X_new - X_old||_2 = 0.19042157223340067\n",
      "iter# = 4, ||X_new - X_old||_2 = 0.1408649175075586\n",
      "iter# = 5, ||X_new - X_old||_2 = 0.10923259182400315\n",
      "iter# = 6, ||X_new - X_old||_2 = 0.08764928644575458\n",
      "iter# = 7, ||X_new - X_old||_2 = 0.07219881897240481\n",
      "iter# = 8, ||X_new - X_old||_2 = 0.06072484526593615\n",
      "iter# = 9, ||X_new - X_old||_2 = 0.051950008893183866\n",
      "iter# = 10, ||X_new - X_old||_2 = 0.045074904827663936\n",
      "iter# = 11, ||X_new - X_old||_2 = 0.0395772766028178\n",
      "iter# = 12, ||X_new - X_old||_2 = 0.03510384598691013\n",
      "iter# = 13, ||X_new - X_old||_2 = 0.031408589961035994\n",
      "iter# = 14, ||X_new - X_old||_2 = 0.028315855413469117\n",
      "iter# = 15, ||X_new - X_old||_2 = 0.025697468009438364\n",
      "iter# = 16, ||X_new - X_old||_2 = 0.023458071290856655\n",
      "iter# = 17, ||X_new - X_old||_2 = 0.021525481828082442\n",
      "iter# = 18, ||X_new - X_old||_2 = 0.019844194774705975\n",
      "iter# = 19, ||X_new - X_old||_2 = 0.01837091968796787\n",
      "iter# = 20, ||X_new - X_old||_2 = 0.017071454442140966\n",
      "iter# = 21, ||X_new - X_old||_2 = 0.015918458769299985\n",
      "iter# = 22, ||X_new - X_old||_2 = 0.014889843581980703\n",
      "iter# = 23, ||X_new - X_old||_2 = 0.013967588752301334\n",
      "iter# = 24, ||X_new - X_old||_2 = 0.013136863555811312\n",
      "iter# = 25, ||X_new - X_old||_2 = 0.012385363958815348\n",
      "iter# = 26, ||X_new - X_old||_2 = 0.011702807333371838\n",
      "iter# = 27, ||X_new - X_old||_2 = 0.011080542899020494\n",
      "iter# = 28, ||X_new - X_old||_2 = 0.010511248245068924\n",
      "iter# = 29, ||X_new - X_old||_2 = 0.009988690599937431\n",
      "iter# = 30, ||X_new - X_old||_2 = 0.009507537318228789\n",
      "iter# = 31, ||X_new - X_old||_2 = 0.009063204156818189\n",
      "iter# = 32, ||X_new - X_old||_2 = 0.00865173284099175\n",
      "iter# = 33, ||X_new - X_old||_2 = 0.00826969153725273\n",
      "iter# = 34, ||X_new - X_old||_2 = 0.007914093392701178\n",
      "iter# = 35, ||X_new - X_old||_2 = 0.00758232943770994\n",
      "iter# = 36, ||X_new - X_old||_2 = 0.007272112993837629\n",
      "iter# = 37, ||X_new - X_old||_2 = 0.006981433362977846\n",
      "iter# = 38, ||X_new - X_old||_2 = 0.0067085170534453105\n",
      "iter# = 39, ||X_new - X_old||_2 = 0.006451795164672022\n",
      "iter# = 40, ||X_new - X_old||_2 = 0.0062098758335445\n",
      "iter# = 41, ||X_new - X_old||_2 = 0.005981520863419379\n",
      "iter# = 42, ||X_new - X_old||_2 = 0.005765625826993655\n",
      "iter# = 43, ||X_new - X_old||_2 = 0.00556120306790476\n",
      "iter# = 44, ||X_new - X_old||_2 = 0.005367367131770016\n",
      "iter# = 45, ||X_new - X_old||_2 = 0.005183322241622568\n",
      "iter# = 46, ||X_new - X_old||_2 = 0.005008351500246819\n",
      "iter# = 47, ||X_new - X_old||_2 = 0.004841807556357846\n",
      "iter# = 48, ||X_new - X_old||_2 = 0.004683104515702029\n",
      "iter# = 49, ||X_new - X_old||_2 = 0.004531710914142977\n",
      "iter# = 50, ||X_new - X_old||_2 = 0.004387143599259584\n",
      "iter# = 51, ||X_new - X_old||_2 = 0.004248962391253961\n",
      "iter# = 52, ||X_new - X_old||_2 = 0.004116765414016618\n",
      "iter# = 53, ||X_new - X_old||_2 = 0.003990185003865642\n",
      "iter# = 54, ||X_new - X_old||_2 = 0.0038688841173489487\n",
      "iter# = 55, ||X_new - X_old||_2 = 0.0037525531711337214\n",
      "iter# = 56, ||X_new - X_old||_2 = 0.003640907256742052\n",
      "iter# = 57, ||X_new - X_old||_2 = 0.003533683681128941\n",
      "iter# = 58, ||X_new - X_old||_2 = 0.0034306397910266956\n",
      "iter# = 59, ||X_new - X_old||_2 = 0.003331551044867332\n",
      "iter# = 60, ||X_new - X_old||_2 = 0.003236209301085669\n",
      "iter# = 61, ||X_new - X_old||_2 = 0.003144421295868789\n",
      "iter# = 62, ||X_new - X_old||_2 = 0.0030560072870389155\n",
      "iter# = 63, ||X_new - X_old||_2 = 0.002970799843867126\n",
      "iter# = 64, ||X_new - X_old||_2 = 0.00288864276527909\n",
      "iter# = 65, ||X_new - X_old||_2 = 0.0028093901111974216\n",
      "iter# = 66, ||X_new - X_old||_2 = 0.0027329053337347294\n",
      "iter# = 67, ||X_new - X_old||_2 = 0.0026590604966436507\n",
      "iter# = 68, ||X_new - X_old||_2 = 0.0025877355729005255\n",
      "iter# = 69, ||X_new - X_old||_2 = 0.002518817811559433\n",
      "iter# = 70, ||X_new - X_old||_2 = 0.0024522011661100088\n",
      "iter# = 71, ||X_new - X_old||_2 = 0.0023877857775327326\n",
      "iter# = 72, ||X_new - X_old||_2 = 0.002325477506056831\n",
      "iter# = 73, ||X_new - X_old||_2 = 0.002265187506358809\n",
      "iter# = 74, ||X_new - X_old||_2 = 0.0022068318415573197\n",
      "iter# = 75, ||X_new - X_old||_2 = 0.0021503311319111987\n",
      "iter# = 76, ||X_new - X_old||_2 = 0.0020956102346028757\n",
      "iter# = 77, ||X_new - X_old||_2 = 0.0020425979514028855\n",
      "iter# = 78, ||X_new - X_old||_2 = 0.001991226761388133\n",
      "iter# = 79, ||X_new - X_old||_2 = 0.001941432576190472\n",
      "iter# = 80, ||X_new - X_old||_2 = 0.0018931545155524802\n",
      "iter# = 81, ||X_new - X_old||_2 = 0.0018463347011958425\n",
      "iter# = 82, ||X_new - X_old||_2 = 0.0018009180672392713\n",
      "iter# = 83, ||X_new - X_old||_2 = 0.0017568521855923155\n",
      "iter# = 84, ||X_new - X_old||_2 = 0.0017140871049095227\n",
      "iter# = 85, ||X_new - X_old||_2 = 0.00167257520185631\n",
      "iter# = 86, ||X_new - X_old||_2 = 0.001632271043556608\n",
      "iter# = 87, ||X_new - X_old||_2 = 0.0015931312602136438\n",
      "iter# = 88, ||X_new - X_old||_2 = 0.0015551144270025514\n",
      "iter# = 89, ||X_new - X_old||_2 = 0.0015181809544167445\n",
      "iter# = 90, ||X_new - X_old||_2 = 0.0014822929863410289\n",
      "iter# = 91, ||X_new - X_old||_2 = 0.0014474143051925487\n",
      "iter# = 92, ||X_new - X_old||_2 = 0.0014135102435334185\n",
      "iter# = 93, ||X_new - X_old||_2 = 0.0013805476016209132\n",
      "iter# = 94, ||X_new - X_old||_2 = 0.0013484945704107876\n",
      "iter# = 95, ||X_new - X_old||_2 = 0.0013173206595733773\n",
      "iter# = 96, ||X_new - X_old||_2 = 0.0012869966301267345\n",
      "iter# = 97, ||X_new - X_old||_2 = 0.0012574944313251746\n",
      "iter# = 98, ||X_new - X_old||_2 = 0.0012287871414744995\n",
      "iter# = 99, ||X_new - X_old||_2 = 0.0012008489123797308\n",
      "iter# = 100, ||X_new - X_old||_2 = 0.0011736549171466617\n",
      "iter# = 101, ||X_new - X_old||_2 = 0.0011471813010992561\n",
      "iter# = 102, ||X_new - X_old||_2 = 0.0011214051355773976\n",
      "iter# = 103, ||X_new - X_old||_2 = 0.0010963043744149237\n",
      "iter# = 104, ||X_new - X_old||_2 = 0.0010718578129067873\n",
      "iter# = 105, ||X_new - X_old||_2 = 0.0010480450490913133\n",
      "iter# = 106, ||X_new - X_old||_2 = 0.0010248464471903234\n",
      "iter# = 107, ||X_new - X_old||_2 = 0.0010022431030595378\n",
      "Number of steps: 109\n",
      "iter# = 0, ||X_new - X_old||_2 = 1.0\n",
      "iter# = 1, ||X_new - X_old||_2 = 0.22094023904309312\n",
      "iter# = 2, ||X_new - X_old||_2 = 0.11717488990168895\n",
      "iter# = 3, ||X_new - X_old||_2 = 0.08836803993600682\n",
      "iter# = 4, ||X_new - X_old||_2 = 0.07220690941432348\n",
      "iter# = 5, ||X_new - X_old||_2 = 0.06191681627583792\n",
      "iter# = 6, ||X_new - X_old||_2 = 0.05417615764146806\n",
      "iter# = 7, ||X_new - X_old||_2 = 0.04737893579320152\n",
      "iter# = 8, ||X_new - X_old||_2 = 0.043089805586688144\n",
      "iter# = 9, ||X_new - X_old||_2 = 0.03907150958900788\n",
      "iter# = 10, ||X_new - X_old||_2 = 0.035672589187330184\n",
      "iter# = 11, ||X_new - X_old||_2 = 0.0330367358646051\n",
      "iter# = 12, ||X_new - X_old||_2 = 0.030470743907675547\n",
      "iter# = 13, ||X_new - X_old||_2 = 0.028693958078162208\n",
      "iter# = 14, ||X_new - X_old||_2 = 0.026919504763777125\n",
      "iter# = 15, ||X_new - X_old||_2 = 0.02542253515362455\n",
      "iter# = 16, ||X_new - X_old||_2 = 0.023947381134447825\n",
      "iter# = 17, ||X_new - X_old||_2 = 0.022642428199317288\n",
      "iter# = 18, ||X_new - X_old||_2 = 0.021409970303368074\n",
      "iter# = 19, ||X_new - X_old||_2 = 0.02028600850116338\n",
      "iter# = 20, ||X_new - X_old||_2 = 0.019354733248377613\n",
      "iter# = 21, ||X_new - X_old||_2 = 0.018483173201506185\n",
      "iter# = 22, ||X_new - X_old||_2 = 0.017660838823782367\n",
      "iter# = 23, ||X_new - X_old||_2 = 0.01689127849121232\n",
      "iter# = 24, ||X_new - X_old||_2 = 0.0162803714289599\n",
      "iter# = 25, ||X_new - X_old||_2 = 0.015679094705859143\n",
      "iter# = 26, ||X_new - X_old||_2 = 0.015071608622507697\n",
      "iter# = 27, ||X_new - X_old||_2 = 0.014574942402575553\n",
      "iter# = 28, ||X_new - X_old||_2 = 0.014104125133016373\n",
      "iter# = 29, ||X_new - X_old||_2 = 0.01365847006167394\n",
      "iter# = 30, ||X_new - X_old||_2 = 0.013193291914469099\n",
      "iter# = 31, ||X_new - X_old||_2 = 0.012781342519780551\n",
      "iter# = 32, ||X_new - X_old||_2 = 0.012405383469018575\n",
      "iter# = 33, ||X_new - X_old||_2 = 0.01204813586914568\n",
      "iter# = 34, ||X_new - X_old||_2 = 0.011633143038551431\n",
      "iter# = 35, ||X_new - X_old||_2 = 0.011301721297372164\n",
      "iter# = 36, ||X_new - X_old||_2 = 0.010961827370743875\n",
      "iter# = 37, ||X_new - X_old||_2 = 0.010621118091363386\n",
      "iter# = 38, ||X_new - X_old||_2 = 0.01034856167464523\n",
      "iter# = 39, ||X_new - X_old||_2 = 0.010087142485641722\n",
      "iter# = 40, ||X_new - X_old||_2 = 0.00983780694336997\n",
      "iter# = 41, ||X_new - X_old||_2 = 0.00959906789135859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 42, ||X_new - X_old||_2 = 0.009370049350073505\n",
      "iter# = 43, ||X_new - X_old||_2 = 0.009150093786700864\n",
      "iter# = 44, ||X_new - X_old||_2 = 0.00893865250461487\n",
      "iter# = 45, ||X_new - X_old||_2 = 0.008697090783858163\n",
      "iter# = 46, ||X_new - X_old||_2 = 0.0084995773327213\n",
      "iter# = 47, ||X_new - X_old||_2 = 0.00831216693508949\n",
      "iter# = 48, ||X_new - X_old||_2 = 0.008132272839460747\n",
      "iter# = 49, ||X_new - X_old||_2 = 0.007959020190575304\n",
      "iter# = 50, ||X_new - X_old||_2 = 0.007791923419984519\n",
      "iter# = 51, ||X_new - X_old||_2 = 0.0076306269093454025\n",
      "iter# = 52, ||X_new - X_old||_2 = 0.007474833309679991\n",
      "iter# = 53, ||X_new - X_old||_2 = 0.007324279199067172\n",
      "iter# = 54, ||X_new - X_old||_2 = 0.007178724537518881\n",
      "iter# = 55, ||X_new - X_old||_2 = 0.0070379471541339575\n",
      "iter# = 56, ||X_new - X_old||_2 = 0.006901739390127149\n",
      "iter# = 57, ||X_new - X_old||_2 = 0.006769905793801642\n",
      "iter# = 58, ||X_new - X_old||_2 = 0.006642261370549708\n",
      "iter# = 59, ||X_new - X_old||_2 = 0.006513420156386552\n",
      "iter# = 60, ||X_new - X_old||_2 = 0.006381759340409127\n",
      "iter# = 61, ||X_new - X_old||_2 = 0.006266615967078102\n",
      "iter# = 62, ||X_new - X_old||_2 = 0.006145990747693191\n",
      "iter# = 63, ||X_new - X_old||_2 = 0.006026595203863814\n",
      "iter# = 64, ||X_new - X_old||_2 = 0.005923317525073292\n",
      "iter# = 65, ||X_new - X_old||_2 = 0.00582198392512709\n",
      "iter# = 66, ||X_new - X_old||_2 = 0.005723825748194169\n",
      "iter# = 67, ||X_new - X_old||_2 = 0.00562852385168318\n",
      "iter# = 68, ||X_new - X_old||_2 = 0.005535899094312869\n",
      "iter# = 69, ||X_new - X_old||_2 = 0.00544581555676831\n",
      "iter# = 70, ||X_new - X_old||_2 = 0.005358157784464265\n",
      "iter# = 71, ||X_new - X_old||_2 = 0.005272821207249168\n",
      "iter# = 72, ||X_new - X_old||_2 = 0.005189706368594808\n",
      "iter# = 73, ||X_new - X_old||_2 = 0.005108712226618117\n",
      "iter# = 74, ||X_new - X_old||_2 = 0.005021206163817819\n",
      "iter# = 75, ||X_new - X_old||_2 = 0.0049365868744824515\n",
      "iter# = 76, ||X_new - X_old||_2 = 0.004863500577870796\n",
      "iter# = 77, ||X_new - X_old||_2 = 0.004790893452683187\n",
      "iter# = 78, ||X_new - X_old||_2 = 0.0047203103648924445\n",
      "iter# = 79, ||X_new - X_old||_2 = 0.004651533361062606\n",
      "iter# = 80, ||X_new - X_old||_2 = 0.004584453302693923\n",
      "iter# = 81, ||X_new - X_old||_2 = 0.004518989955410251\n",
      "iter# = 82, ||X_new - X_old||_2 = 0.004455076869818358\n",
      "iter# = 83, ||X_new - X_old||_2 = 0.004392655521052744\n",
      "iter# = 84, ||X_new - X_old||_2 = 0.004331672674808774\n",
      "iter# = 85, ||X_new - X_old||_2 = 0.004272079052421891\n",
      "iter# = 86, ||X_new - X_old||_2 = 0.004213828603610972\n",
      "iter# = 87, ||X_new - X_old||_2 = 0.0041568781235978795\n",
      "iter# = 88, ||X_new - X_old||_2 = 0.004101187176361071\n",
      "iter# = 89, ||X_new - X_old||_2 = 0.0040425374532598885\n",
      "iter# = 90, ||X_new - X_old||_2 = 0.003984130167063037\n",
      "iter# = 91, ||X_new - X_old||_2 = 0.00392919065118136\n",
      "iter# = 92, ||X_new - X_old||_2 = 0.0038780438183677\n",
      "iter# = 93, ||X_new - X_old||_2 = 0.0038282862471215764\n",
      "iter# = 94, ||X_new - X_old||_2 = 0.00377969269794649\n",
      "iter# = 95, ||X_new - X_old||_2 = 0.003732172186531397\n",
      "iter# = 96, ||X_new - X_old||_2 = 0.003685667627009627\n",
      "iter# = 97, ||X_new - X_old||_2 = 0.0036407365520170127\n",
      "iter# = 98, ||X_new - X_old||_2 = 0.0036003116244323293\n",
      "iter# = 99, ||X_new - X_old||_2 = 0.0035524984792258347\n",
      "iter# = 100, ||X_new - X_old||_2 = 0.003513764273359179\n",
      "iter# = 101, ||X_new - X_old||_2 = 0.0034677112474334353\n",
      "iter# = 102, ||X_new - X_old||_2 = 0.003429861946671546\n",
      "iter# = 103, ||X_new - X_old||_2 = 0.0033894047380687775\n",
      "iter# = 104, ||X_new - X_old||_2 = 0.003349805707187738\n",
      "iter# = 105, ||X_new - X_old||_2 = 0.003310972265471186\n",
      "iter# = 106, ||X_new - X_old||_2 = 0.0032728835355785506\n",
      "iter# = 107, ||X_new - X_old||_2 = 0.003235519947374571\n",
      "iter# = 108, ||X_new - X_old||_2 = 0.00319886290961603\n",
      "iter# = 109, ||X_new - X_old||_2 = 0.0031628945046818413\n",
      "iter# = 110, ||X_new - X_old||_2 = 0.0031275973835809753\n",
      "iter# = 111, ||X_new - X_old||_2 = 0.0030929547130537118\n",
      "iter# = 112, ||X_new - X_old||_2 = 0.0030589501418217843\n",
      "iter# = 113, ||X_new - X_old||_2 = 0.0030255677760638224\n",
      "iter# = 114, ||X_new - X_old||_2 = 0.0029927921604771812\n",
      "iter# = 115, ||X_new - X_old||_2 = 0.0029606082632624106\n",
      "iter# = 116, ||X_new - X_old||_2 = 0.0029290014640554586\n",
      "iter# = 117, ||X_new - X_old||_2 = 0.0028979575441177873\n",
      "iter# = 118, ||X_new - X_old||_2 = 0.002867462678240895\n",
      "iter# = 119, ||X_new - X_old||_2 = 0.0028375034278942672\n",
      "iter# = 120, ||X_new - X_old||_2 = 0.002808066735239663\n",
      "iter# = 121, ||X_new - X_old||_2 = 0.0027791399176589114\n",
      "iter# = 122, ||X_new - X_old||_2 = 0.002750710662552063\n",
      "iter# = 123, ||X_new - X_old||_2 = 0.002722767022221451\n",
      "iter# = 124, ||X_new - X_old||_2 = 0.0026952974087513493\n",
      "iter# = 125, ||X_new - X_old||_2 = 0.002668290589043109\n",
      "iter# = 126, ||X_new - X_old||_2 = 0.0026417356806258834\n",
      "iter# = 127, ||X_new - X_old||_2 = 0.00261348781942994\n",
      "iter# = 128, ||X_new - X_old||_2 = 0.0025864933905832173\n",
      "iter# = 129, ||X_new - X_old||_2 = 0.002560737123943885\n",
      "iter# = 130, ||X_new - X_old||_2 = 0.002535830177363636\n",
      "iter# = 131, ||X_new - X_old||_2 = 0.002511395148081389\n",
      "iter# = 132, ||X_new - X_old||_2 = 0.002487384709948325\n",
      "iter# = 133, ||X_new - X_old||_2 = 0.0024637755731455754\n",
      "iter# = 134, ||X_new - X_old||_2 = 0.002440551733203418\n",
      "iter# = 135, ||X_new - X_old||_2 = 0.0024177005692050425\n",
      "iter# = 136, ||X_new - X_old||_2 = 0.0023952113060880706\n",
      "iter# = 137, ||X_new - X_old||_2 = 0.0023730742945370937\n",
      "iter# = 138, ||X_new - X_old||_2 = 0.0023512806334051273\n",
      "iter# = 139, ||X_new - X_old||_2 = 0.0023298219527602975\n",
      "iter# = 140, ||X_new - X_old||_2 = 0.0023086902784075374\n",
      "iter# = 141, ||X_new - X_old||_2 = 0.002287877939751187\n",
      "iter# = 142, ||X_new - X_old||_2 = 0.0022673775007348625\n",
      "iter# = 143, ||X_new - X_old||_2 = 0.0022471817018873477\n",
      "iter# = 144, ||X_new - X_old||_2 = 0.0022272834050802983\n",
      "iter# = 145, ||X_new - X_old||_2 = 0.0022076755337078614\n",
      "iter# = 146, ||X_new - X_old||_2 = 0.0021883509999376036\n",
      "iter# = 147, ||X_new - X_old||_2 = 0.002169302607474949\n",
      "iter# = 148, ||X_new - X_old||_2 = 0.002150522911102046\n",
      "iter# = 149, ||X_new - X_old||_2 = 0.0021320040000603105\n",
      "iter# = 150, ||X_new - X_old||_2 = 0.0021137371427018105\n",
      "iter# = 151, ||X_new - X_old||_2 = 0.0020957121649827462\n",
      "iter# = 152, ||X_new - X_old||_2 = 0.0020779162811921112\n",
      "iter# = 153, ||X_new - X_old||_2 = 0.0020603316932230665\n",
      "iter# = 154, ||X_new - X_old||_2 = 0.002042930118214766\n",
      "iter# = 155, ||X_new - X_old||_2 = 0.0020256593249162722\n",
      "iter# = 156, ||X_new - X_old||_2 = 0.0020051021329117965\n",
      "iter# = 157, ||X_new - X_old||_2 = 0.001986753580909411\n",
      "iter# = 158, ||X_new - X_old||_2 = 0.0019700763492402633\n",
      "iter# = 159, ||X_new - X_old||_2 = 0.001953890802545427\n",
      "iter# = 160, ||X_new - X_old||_2 = 0.001938016518741705\n",
      "iter# = 161, ||X_new - X_old||_2 = 0.0019224076785553576\n",
      "iter# = 162, ||X_new - X_old||_2 = 0.0019070422423521703\n",
      "iter# = 163, ||X_new - X_old||_2 = 0.0018919065630005176\n",
      "iter# = 164, ||X_new - X_old||_2 = 0.0018769909905146705\n",
      "iter# = 165, ||X_new - X_old||_2 = 0.0018627773277632058\n",
      "iter# = 166, ||X_new - X_old||_2 = 0.0018504229310612622\n",
      "iter# = 167, ||X_new - X_old||_2 = 0.0018340655903264255\n",
      "iter# = 168, ||X_new - X_old||_2 = 0.0018220488986934145\n",
      "iter# = 169, ||X_new - X_old||_2 = 0.0018060678459154464\n",
      "iter# = 170, ||X_new - X_old||_2 = 0.0017938134737851684\n",
      "iter# = 171, ||X_new - X_old||_2 = 0.001780307957842323\n",
      "iter# = 172, ||X_new - X_old||_2 = 0.0017669404163395074\n",
      "iter# = 173, ||X_new - X_old||_2 = 0.001753747660524832\n",
      "iter# = 174, ||X_new - X_old||_2 = 0.0017407269385172194\n",
      "iter# = 175, ||X_new - X_old||_2 = 0.0017278749260423703\n",
      "iter# = 176, ||X_new - X_old||_2 = 0.001715188397327813\n",
      "iter# = 177, ||X_new - X_old||_2 = 0.0017026642071505456\n",
      "iter# = 178, ||X_new - X_old||_2 = 0.0016902992825375712\n",
      "iter# = 179, ||X_new - X_old||_2 = 0.0016780906197643808\n",
      "iter# = 180, ||X_new - X_old||_2 = 0.0016660352827342398\n",
      "iter# = 181, ||X_new - X_old||_2 = 0.001654130401767374\n",
      "iter# = 182, ||X_new - X_old||_2 = 0.0016423731726005523\n",
      "iter# = 183, ||X_new - X_old||_2 = 0.001630760855501869\n",
      "iter# = 184, ||X_new - X_old||_2 = 0.0016192907744532305\n",
      "iter# = 185, ||X_new - X_old||_2 = 0.0016079603163709742\n",
      "iter# = 186, ||X_new - X_old||_2 = 0.0015967669303194227\n",
      "iter# = 187, ||X_new - X_old||_2 = 0.001585708126705466\n",
      "iter# = 188, ||X_new - X_old||_2 = 0.001574781476422309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 189, ||X_new - X_old||_2 = 0.0015639846099262512\n",
      "iter# = 190, ||X_new - X_old||_2 = 0.0015533152162466948\n",
      "iter# = 191, ||X_new - X_old||_2 = 0.0015427710419151077\n",
      "iter# = 192, ||X_new - X_old||_2 = 0.0015323498898218199\n",
      "iter# = 193, ||X_new - X_old||_2 = 0.0015220496179746531\n",
      "iter# = 194, ||X_new - X_old||_2 = 0.0015118681382019685\n",
      "iter# = 195, ||X_new - X_old||_2 = 0.00150180341476302\n",
      "iter# = 196, ||X_new - X_old||_2 = 0.0014918534628807771\n",
      "iter# = 197, ||X_new - X_old||_2 = 0.0014820163472225084\n",
      "iter# = 198, ||X_new - X_old||_2 = 0.0014721502767769904\n",
      "iter# = 199, ||X_new - X_old||_2 = 0.0014618047851766758\n",
      "iter# = 200, ||X_new - X_old||_2 = 0.0014517641741706613\n",
      "iter# = 201, ||X_new - X_old||_2 = 0.001442272008450373\n",
      "iter# = 202, ||X_new - X_old||_2 = 0.0014329435906659737\n",
      "iter# = 203, ||X_new - X_old||_2 = 0.0014237386458474724\n",
      "iter# = 204, ||X_new - X_old||_2 = 0.0014146457569035357\n",
      "iter# = 205, ||X_new - X_old||_2 = 0.00140565890588176\n",
      "iter# = 206, ||X_new - X_old||_2 = 0.0013967740796436803\n",
      "iter# = 207, ||X_new - X_old||_2 = 0.0013879882578008318\n",
      "iter# = 208, ||X_new - X_old||_2 = 0.001379298978479719\n",
      "iter# = 209, ||X_new - X_old||_2 = 0.0013707041220603782\n",
      "iter# = 210, ||X_new - X_old||_2 = 0.00136220179366703\n",
      "iter# = 211, ||X_new - X_old||_2 = 0.0013537902550190396\n",
      "iter# = 212, ||X_new - X_old||_2 = 0.0013454678827554518\n",
      "iter# = 213, ||X_new - X_old||_2 = 0.0013372331417782861\n",
      "iter# = 214, ||X_new - X_old||_2 = 0.0013290845675261722\n",
      "iter# = 215, ||X_new - X_old||_2 = 0.001321020753777214\n",
      "iter# = 216, ||X_new - X_old||_2 = 0.0013130403439813574\n",
      "iter# = 217, ||X_new - X_old||_2 = 0.0013051420249302202\n",
      "iter# = 218, ||X_new - X_old||_2 = 0.0012973245220049426\n",
      "iter# = 219, ||X_new - X_old||_2 = 0.0012895865955251757\n",
      "iter# = 220, ||X_new - X_old||_2 = 0.0012819270378690007\n",
      "iter# = 221, ||X_new - X_old||_2 = 0.0012743446711587485\n",
      "iter# = 222, ||X_new - X_old||_2 = 0.0012668383453636844\n",
      "iter# = 223, ||X_new - X_old||_2 = 0.0012594069367118752\n",
      "iter# = 224, ||X_new - X_old||_2 = 0.0012520493463304744\n",
      "iter# = 225, ||X_new - X_old||_2 = 0.0012447644990896613\n",
      "iter# = 226, ||X_new - X_old||_2 = 0.0012375513425674084\n",
      "iter# = 227, ||X_new - X_old||_2 = 0.001230408846149458\n",
      "iter# = 228, ||X_new - X_old||_2 = 0.0012233360002027395\n",
      "iter# = 229, ||X_new - X_old||_2 = 0.0012163318153466127\n",
      "iter# = 230, ||X_new - X_old||_2 = 0.001209395321772615\n",
      "iter# = 231, ||X_new - X_old||_2 = 0.0012025255686098416\n",
      "iter# = 232, ||X_new - X_old||_2 = 0.0011957216233650196\n",
      "iter# = 233, ||X_new - X_old||_2 = 0.0011889825713639207\n",
      "iter# = 234, ||X_new - X_old||_2 = 0.0011823075152573674\n",
      "iter# = 235, ||X_new - X_old||_2 = 0.0011756955745330826\n",
      "iter# = 236, ||X_new - X_old||_2 = 0.0011691458850683874\n",
      "iter# = 237, ||X_new - X_old||_2 = 0.0011626575987003188\n",
      "iter# = 238, ||X_new - X_old||_2 = 0.0011562298828196396\n",
      "iter# = 239, ||X_new - X_old||_2 = 0.001149861919967804\n",
      "iter# = 240, ||X_new - X_old||_2 = 0.0011435529074826309\n",
      "iter# = 241, ||X_new - X_old||_2 = 0.0011373020571213018\n",
      "iter# = 242, ||X_new - X_old||_2 = 0.0011311085947261713\n",
      "iter# = 243, ||X_new - X_old||_2 = 0.0011249717598900881\n",
      "iter# = 244, ||X_new - X_old||_2 = 0.0011188908056437286\n",
      "iter# = 245, ||X_new - X_old||_2 = 0.0011128649981343008\n",
      "iter# = 246, ||X_new - X_old||_2 = 0.0011068936163416648\n",
      "iter# = 247, ||X_new - X_old||_2 = 0.0011009759517815298\n",
      "iter# = 248, ||X_new - X_old||_2 = 0.0010951113082349922\n",
      "iter# = 249, ||X_new - X_old||_2 = 0.0010892990014719657\n",
      "iter# = 250, ||X_new - X_old||_2 = 0.0010835383589919802\n",
      "iter# = 251, ||X_new - X_old||_2 = 0.0010778287197741197\n",
      "iter# = 252, ||X_new - X_old||_2 = 0.0010721694340274158\n",
      "iter# = 253, ||X_new - X_old||_2 = 0.0010665598629585602\n",
      "iter# = 254, ||X_new - X_old||_2 = 0.00106099937852781\n",
      "iter# = 255, ||X_new - X_old||_2 = 0.0010554873632380817\n",
      "iter# = 256, ||X_new - X_old||_2 = 0.0010500232099052785\n",
      "iter# = 257, ||X_new - X_old||_2 = 0.0010446063214501094\n",
      "iter# = 258, ||X_new - X_old||_2 = 0.0010392361106903137\n",
      "iter# = 259, ||X_new - X_old||_2 = 0.0010339120001402581\n",
      "iter# = 260, ||X_new - X_old||_2 = 0.0010286334218086476\n",
      "iter# = 261, ||X_new - X_old||_2 = 0.001023399817013302\n",
      "iter# = 262, ||X_new - X_old||_2 = 0.001018210636191535\n",
      "iter# = 263, ||X_new - X_old||_2 = 0.0010130653387207262\n",
      "iter# = 264, ||X_new - X_old||_2 = 0.0010079633927379708\n",
      "iter# = 265, ||X_new - X_old||_2 = 0.0010029042749692058\n",
      "Number of steps: 267\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Run algorithm\n",
    "epsilon = 1e-3                # Precision parameter\n",
    "iters = 1000\n",
    "eta = 0.1\n",
    "\n",
    "U, S, V = la.svd(X_star)\n",
    "l = np.sum(S)\n",
    "\n",
    "X_IHT, X_list_IHT, f_list_IHT = matrix_IHT(y, A, r, eta, iters, epsilon, True, X_star)\n",
    "X_NN, X_list_NN, f_list_NN = matrix_nuclear_norm_min(y, A, l, eta, iters, epsilon, True, X_star)\n",
    "\n",
    "# Plot\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "xs_IHT = range(len(X_list_IHT))\n",
    "xs_NN = range(len(X_list_NN))\n",
    "\n",
    "plt.plot(xs_IHT, X_list_IHT, '-o', color = '#3399FF', linewidth = 2, alpha = 0.7) # Blue\n",
    "plt.plot(xs_NN, X_list_NN, '-o', color = '#FF6666', linewidth = 2, alpha = 0.7) # Red\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r\"$\\|x^\\star - \\widehat{x}\\|_2$\")\n",
    "\n",
    "# Make room for the ridiculously large title.\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
