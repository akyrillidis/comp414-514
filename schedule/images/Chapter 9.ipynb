{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuclear norm minimization vs. IHT for low-rank matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.palettes import brewer\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import random\n",
    "from numpy import linalg as la\n",
    "\n",
    "from matplotlib import rc\n",
    "#rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "p = 128  # Matrices of size p x p\n",
    "r = 2   # Sparsity level\n",
    "n = np.ceil(5 * p * r)\n",
    "\n",
    "# Generate a pxp-dimensional zero matrix\n",
    "A = np.random.randn(p, r)\n",
    "B = np.random.randn(p, r)\n",
    "X_star = A.dot(B.T)\n",
    "X_star = (1 / la.norm(X_star, 'fro')) * X_star\n",
    "\n",
    "# Generate matrices for the sensing mechanism\n",
    "A = np.zeros((int(n), p, p))\n",
    "for i in range(int(n)):\n",
    "    C = (1/np.sqrt(n)) * np.random.randn(p, p)\n",
    "    A[i, :, :] = C\n",
    "\n",
    "# print(A[1, :, :])\n",
    "# print(np.squeeze(A[i, :, :]))\n",
    "# print(np.squeeze(A[i, :, :]).shape)\n",
    "# print(1/np.sqrt(n))\n",
    "# Observation model\n",
    "y = np.zeros(int(n))\n",
    "\n",
    "for i in range(int(n)):\n",
    "    B = np.squeeze(A[i, :, :])\n",
    "    y[i] = np.trace(B.dot(X_star.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds, eigs\n",
    "\n",
    "# Hard thresholding function\n",
    "def hardThreshold(X, r):\n",
    "    U, S, V = svds(X, k = r)    \n",
    "    S = np.diag(S)\n",
    "    return U.dot(S.dot(V))\n",
    "\n",
    "def l1normProj(x, l):\n",
    "    assert l > 0, \"Radius lambda must be strictly positive (%d <= 0)\" % l\n",
    "    n, = x.shape  \n",
    "    \n",
    "    u = np.abs(x)                               # compute the vector of absolute values\n",
    "    \n",
    "    if u.sum() <= l:                            # check if v is already a solution    \n",
    "        return x\n",
    "    \n",
    "    u = np.sort(x)[::-1]                        # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    cssv = np.cumsum(u)\n",
    "    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - l))[0][-1]   # get the number of > 0 components of the optimal solution\n",
    "    theta = (float(cssv[rho] - l) / rho).clip(min=0)                 # compute the projection by thresholding v using theta          # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    w = (np.abs(x) - theta).clip(min=0)                 # compute the projection by thresholding v using theta\n",
    "    w *= np.sign(x)    \n",
    "        \n",
    "    return w\n",
    "\n",
    "def proj_nuclear_norm(X, l):\n",
    "    U, S, V = la.svd(X)\n",
    "    S = l1normProj(S, l)\n",
    "    S = np.diag(S)\n",
    "    return U.dot(S.dot(V))\n",
    "    \n",
    "# Returns the value of the objecive function\n",
    "def f(y, A, X):\n",
    "    f_value = 0\n",
    "    n = y.shape[0]\n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])\n",
    "        f_value += 0.5 * (y[i] - np.trace(B.dot(X.T)))**2\n",
    "    return f_value\n",
    "\n",
    "def compute_grad(y, A, X):\n",
    "    n = y.shape[0]\n",
    "    p = A.shape[1]\n",
    "\n",
    "    grad = np.zeros((p, p))\n",
    "    b = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])        \n",
    "        b[i] = y[i] - np.trace(B.dot(X.T))\n",
    "    \n",
    "#     print(b)\n",
    "    for i in range(n):\n",
    "        B = np.squeeze(A[i, :, :])\n",
    "        grad += -b[i] * B;\n",
    "    \n",
    "#     print(grad)\n",
    "    return grad\n",
    "\n",
    "def matrix_IHT(y, A, r, eta, iters, epsilon, verbose, X_star):\n",
    "    # Length of original signal\n",
    "    p = A.shape[1]\n",
    "    # Length of measurement vector\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initial estimate\n",
    "    X_new = np.zeros((p, p))\n",
    "    \n",
    "    X_list, f_list = [1], [f(y, A, X_new)]\n",
    "\n",
    "    for i in range(iters):\n",
    "        X_old = X_new\n",
    "    \n",
    "        # Compute gradient\n",
    "        grad = compute_grad(y, A, X_old)\n",
    "#         print(grad)\n",
    "        # Perform gradient step\n",
    "        X_temp = X_old - eta * grad    \n",
    "    \n",
    "        # Perform hard thresholding step\n",
    "        X_new = hardThreshold(X_temp, r)\n",
    "    \n",
    "        if (la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')) < epsilon:\n",
    "            break\n",
    "                \n",
    "        # Keep track of solutions and objective values\n",
    "        X_list.append(la.norm(X_new - X_star, 'fro'))\n",
    "        f_list.append(f(y, A, X_new))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"iter# = \"+ str(i) + \", ||X_new - X_old||_2 = \" + str(la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')))\n",
    "    \n",
    "    print(\"Number of steps:\", len(f_list))\n",
    "    return X_new, X_list, f_list\n",
    "\n",
    "def matrix_nuclear_norm_min(y, A, l, eta, iters, epsilon, verbose, X_star):\n",
    "    # Length of original signal\n",
    "    p = A.shape[1]\n",
    "    # Length of measurement vector\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initial estimate\n",
    "    X_new = np.zeros((p, p))\n",
    "    \n",
    "    X_list, f_list = [1], [f(y, A, X_new)]\n",
    "\n",
    "    for i in range(iters):\n",
    "        X_old = X_new\n",
    "    \n",
    "        # Compute gradient\n",
    "        grad = compute_grad(y, A, X_old)\n",
    "    \n",
    "        # Perform gradient step\n",
    "        X_temp = X_old - eta * grad    \n",
    "    \n",
    "        # Perform hard thresholding step\n",
    "        X_new = proj_nuclear_norm(X_temp, l)\n",
    "    \n",
    "        if (la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')) < epsilon:\n",
    "            break\n",
    "                \n",
    "        # Keep track of solutions and objective values\n",
    "        X_list.append(la.norm(X_new - X_star, 'fro'))\n",
    "        f_list.append(f(y, A, X_new))\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"iter# = \"+ str(i) + \", ||X_new - X_old||_2 = \" + str(la.norm(X_new - X_old, 'fro') / la.norm(X_new, 'fro')))\n",
    "    \n",
    "    print(\"Number of steps:\", len(f_list))\n",
    "    return X_new, X_list, f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 0, ||X_new - X_old||_2 = 1.0\n",
      "iter# = 1, ||X_new - X_old||_2 = 0.4518679995157357\n",
      "iter# = 2, ||X_new - X_old||_2 = 0.2739957749433331\n",
      "iter# = 3, ||X_new - X_old||_2 = 0.18822046533283343\n",
      "iter# = 4, ||X_new - X_old||_2 = 0.1389257321280462\n",
      "iter# = 5, ||X_new - X_old||_2 = 0.1075954839104845\n",
      "iter# = 6, ||X_new - X_old||_2 = 0.086318398744692\n",
      "iter# = 7, ||X_new - X_old||_2 = 0.07116170583905462\n",
      "iter# = 8, ||X_new - X_old||_2 = 0.059960849595855695\n",
      "iter# = 9, ||X_new - X_old||_2 = 0.051434369879917625\n",
      "iter# = 10, ||X_new - X_old||_2 = 0.04478103830700531\n",
      "iter# = 11, ||X_new - X_old||_2 = 0.039478192573684165\n",
      "iter# = 12, ||X_new - X_old||_2 = 0.03517310135324321\n",
      "iter# = 13, ||X_new - X_old||_2 = 0.031620946890399675\n",
      "iter# = 14, ||X_new - X_old||_2 = 0.028647725442922538\n",
      "iter# = 15, ||X_new - X_old||_2 = 0.026127188220692543\n",
      "iter# = 16, ||X_new - X_old||_2 = 0.023966046912007113\n",
      "iter# = 17, ||X_new - X_old||_2 = 0.022094224838561747\n",
      "iter# = 18, ||X_new - X_old||_2 = 0.02045828482704718\n",
      "iter# = 19, ||X_new - X_old||_2 = 0.019016910195007012\n",
      "iter# = 20, ||X_new - X_old||_2 = 0.01773774284777619\n",
      "iter# = 21, ||X_new - X_old||_2 = 0.016595136127727506\n",
      "iter# = 22, ||X_new - X_old||_2 = 0.01556853494087343\n",
      "iter# = 23, ||X_new - X_old||_2 = 0.014641292681198625\n",
      "iter# = 24, ||X_new - X_old||_2 = 0.013799796568986063\n",
      "iter# = 25, ||X_new - X_old||_2 = 0.013032813547590581\n",
      "iter# = 26, ||X_new - X_old||_2 = 0.012330995788368373\n",
      "iter# = 27, ||X_new - X_old||_2 = 0.011686502987061006\n",
      "iter# = 28, ||X_new - X_old||_2 = 0.011092711023725324\n",
      "iter# = 29, ||X_new - X_old||_2 = 0.010543985127423116\n",
      "iter# = 30, ||X_new - X_old||_2 = 0.010035501681789214\n",
      "iter# = 31, ||X_new - X_old||_2 = 0.009563107046234158\n",
      "iter# = 32, ||X_new - X_old||_2 = 0.009123204794401367\n",
      "iter# = 33, ||X_new - X_old||_2 = 0.008712664953551531\n",
      "iter# = 34, ||X_new - X_old||_2 = 0.008328750415815584\n",
      "iter# = 35, ||X_new - X_old||_2 = 0.007969056856879146\n",
      "iter# = 36, ||X_new - X_old||_2 = 0.007631463359287502\n",
      "iter# = 37, ||X_new - X_old||_2 = 0.007314091580151966\n",
      "iter# = 38, ||X_new - X_old||_2 = 0.0070152717859505095\n",
      "iter# = 39, ||X_new - X_old||_2 = 0.006733514442753326\n",
      "iter# = 40, ||X_new - X_old||_2 = 0.0064674863290341625\n",
      "iter# = 41, ||X_new - X_old||_2 = 0.006215990352339735\n",
      "iter# = 42, ||X_new - X_old||_2 = 0.0059779484166164855\n",
      "iter# = 43, ||X_new - X_old||_2 = 0.00575238681579227\n",
      "iter# = 44, ||X_new - X_old||_2 = 0.005538423730093131\n",
      "iter# = 45, ||X_new - X_old||_2 = 0.0053352584810467\n",
      "iter# = 46, ||X_new - X_old||_2 = 0.005142162264140698\n",
      "iter# = 47, ||X_new - X_old||_2 = 0.004958470128345153\n",
      "iter# = 48, ||X_new - X_old||_2 = 0.004783574012019362\n",
      "iter# = 49, ||X_new - X_old||_2 = 0.004616916677205954\n",
      "iter# = 50, ||X_new - X_old||_2 = 0.0044579864106929195\n",
      "iter# = 51, ||X_new - X_old||_2 = 0.004306312381686842\n",
      "iter# = 52, ||X_new - X_old||_2 = 0.004161460563561188\n",
      "iter# = 53, ||X_new - X_old||_2 = 0.004023030141619232\n",
      "iter# = 54, ||X_new - X_old||_2 = 0.0038906503408074273\n",
      "iter# = 55, ||X_new - X_old||_2 = 0.0037639776172683284\n",
      "iter# = 56, ||X_new - X_old||_2 = 0.003642693165928442\n",
      "iter# = 57, ||X_new - X_old||_2 = 0.0035265007032749584\n",
      "iter# = 58, ||X_new - X_old||_2 = 0.003415124490325353\n",
      "iter# = 59, ||X_new - X_old||_2 = 0.003308307565728017\n",
      "iter# = 60, ||X_new - X_old||_2 = 0.003205810163102196\n",
      "iter# = 61, ||X_new - X_old||_2 = 0.0031074082902786504\n",
      "iter# = 62, ||X_new - X_old||_2 = 0.003012892451109795\n",
      "iter# = 63, ||X_new - X_old||_2 = 0.0029220664931030958\n",
      "iter# = 64, ||X_new - X_old||_2 = 0.00283474656632167\n",
      "iter# = 65, ||X_new - X_old||_2 = 0.0027507601808991144\n",
      "iter# = 66, ||X_new - X_old||_2 = 0.0026699453521213585\n",
      "iter# = 67, ||X_new - X_old||_2 = 0.0025921498234416185\n",
      "iter# = 68, ||X_new - X_old||_2 = 0.0025172303589841346\n",
      "iter# = 69, ||X_new - X_old||_2 = 0.002445052098143927\n",
      "iter# = 70, ||X_new - X_old||_2 = 0.0023754879657868705\n",
      "iter# = 71, ||X_new - X_old||_2 = 0.002308418132329316\n",
      "iter# = 72, ||X_new - X_old||_2 = 0.0022437295186623204\n",
      "iter# = 73, ||X_new - X_old||_2 = 0.0021813153414704588\n",
      "iter# = 74, ||X_new - X_old||_2 = 0.0021210746950101346\n",
      "iter# = 75, ||X_new - X_old||_2 = 0.0020629121658530284\n",
      "iter# = 76, ||X_new - X_old||_2 = 0.002006737477502127\n",
      "iter# = 77, ||X_new - X_old||_2 = 0.0019524651621206253\n",
      "iter# = 78, ||X_new - X_old||_2 = 0.001900014256913639\n",
      "iter# = 79, ||X_new - X_old||_2 = 0.0018493080229724562\n",
      "iter# = 80, ||X_new - X_old||_2 = 0.001800273684612511\n",
      "iter# = 81, ||X_new - X_old||_2 = 0.0017528421874464272\n",
      "iter# = 82, ||X_new - X_old||_2 = 0.001706947973606667\n",
      "iter# = 83, ||X_new - X_old||_2 = 0.001662528772699343\n",
      "iter# = 84, ||X_new - X_old||_2 = 0.001619525407195836\n",
      "iter# = 85, ||X_new - X_old||_2 = 0.0015778816111104573\n",
      "iter# = 86, ||X_new - X_old||_2 = 0.0015375438609088246\n",
      "iter# = 87, ||X_new - X_old||_2 = 0.0014984612176940232\n",
      "iter# = 88, ||X_new - X_old||_2 = 0.0014605851798084881\n",
      "iter# = 89, ||X_new - X_old||_2 = 0.0014238695450597152\n",
      "iter# = 90, ||X_new - X_old||_2 = 0.0013882702818553124\n",
      "iter# = 91, ||X_new - X_old||_2 = 0.0013537454085900636\n",
      "iter# = 92, ||X_new - X_old||_2 = 0.0013202548806842311\n",
      "iter# = 93, ||X_new - X_old||_2 = 0.0012877604847290902\n",
      "iter# = 94, ||X_new - X_old||_2 = 0.001256225739224852\n",
      "iter# = 95, ||X_new - X_old||_2 = 0.0012256158014646195\n",
      "iter# = 96, ||X_new - X_old||_2 = 0.0011958973801192462\n",
      "iter# = 97, ||X_new - X_old||_2 = 0.0011670386531497377\n",
      "iter# = 98, ||X_new - X_old||_2 = 0.0011390091906709864\n",
      "iter# = 99, ||X_new - X_old||_2 = 0.0011117798824407886\n",
      "iter# = 100, ||X_new - X_old||_2 = 0.0010853228696630932\n",
      "iter# = 101, ||X_new - X_old||_2 = 0.0010596114808211106\n",
      "iter# = 102, ||X_new - X_old||_2 = 0.0010346201712732434\n",
      "iter# = 103, ||X_new - X_old||_2 = 0.0010103244663703045\n",
      "Number of steps: 105\n",
      "iter# = 0, ||X_new - X_old||_2 = 1.0\n",
      "iter# = 1, ||X_new - X_old||_2 = 0.22122828125670344\n",
      "iter# = 2, ||X_new - X_old||_2 = 0.11735458071004329\n",
      "iter# = 3, ||X_new - X_old||_2 = 0.08897449653789541\n",
      "iter# = 4, ||X_new - X_old||_2 = 0.07272651212920085\n",
      "iter# = 5, ||X_new - X_old||_2 = 0.062397386428856734\n",
      "iter# = 6, ||X_new - X_old||_2 = 0.05452725728415977\n",
      "iter# = 7, ||X_new - X_old||_2 = 0.04850597691260648\n",
      "iter# = 8, ||X_new - X_old||_2 = 0.04332488587537615\n",
      "iter# = 9, ||X_new - X_old||_2 = 0.03911703190368195\n",
      "iter# = 10, ||X_new - X_old||_2 = 0.03623399869321124\n",
      "iter# = 11, ||X_new - X_old||_2 = 0.03346567582888579\n",
      "iter# = 12, ||X_new - X_old||_2 = 0.030927875705529597\n",
      "iter# = 13, ||X_new - X_old||_2 = 0.02871612516262163\n",
      "iter# = 14, ||X_new - X_old||_2 = 0.02703813899843544\n",
      "iter# = 15, ||X_new - X_old||_2 = 0.02559135888273122\n",
      "iter# = 16, ||X_new - X_old||_2 = 0.024065439348540888\n",
      "iter# = 17, ||X_new - X_old||_2 = 0.02283770748043926\n",
      "iter# = 18, ||X_new - X_old||_2 = 0.021687635561918547\n",
      "iter# = 19, ||X_new - X_old||_2 = 0.020533937333688468\n",
      "iter# = 20, ||X_new - X_old||_2 = 0.019399905914057717\n",
      "iter# = 21, ||X_new - X_old||_2 = 0.018465149130222274\n",
      "iter# = 22, ||X_new - X_old||_2 = 0.017654908505619214\n",
      "iter# = 23, ||X_new - X_old||_2 = 0.01695760946274866\n",
      "iter# = 24, ||X_new - X_old||_2 = 0.016231072103756374\n",
      "iter# = 25, ||X_new - X_old||_2 = 0.01556727096751188\n",
      "iter# = 26, ||X_new - X_old||_2 = 0.01500514001405474\n",
      "iter# = 27, ||X_new - X_old||_2 = 0.014383789902811321\n",
      "iter# = 28, ||X_new - X_old||_2 = 0.013894557632997585\n",
      "iter# = 29, ||X_new - X_old||_2 = 0.013438479026834418\n",
      "iter# = 30, ||X_new - X_old||_2 = 0.012952728929475478\n",
      "iter# = 31, ||X_new - X_old||_2 = 0.012530966224208786\n",
      "iter# = 32, ||X_new - X_old||_2 = 0.012137026191412539\n",
      "iter# = 33, ||X_new - X_old||_2 = 0.011734867694572989\n",
      "iter# = 34, ||X_new - X_old||_2 = 0.011397625047694246\n",
      "iter# = 35, ||X_new - X_old||_2 = 0.011018569692448242\n",
      "iter# = 36, ||X_new - X_old||_2 = 0.010715977160367944\n",
      "iter# = 37, ||X_new - X_old||_2 = 0.010430751483758363\n",
      "iter# = 38, ||X_new - X_old||_2 = 0.010158831668005248\n",
      "iter# = 39, ||X_new - X_old||_2 = 0.009898574136851749\n",
      "iter# = 40, ||X_new - X_old||_2 = 0.009646016656946059\n",
      "iter# = 41, ||X_new - X_old||_2 = 0.009355911772883014\n",
      "iter# = 42, ||X_new - X_old||_2 = 0.009127256784091719\n",
      "iter# = 43, ||X_new - X_old||_2 = 0.008910351714481205\n",
      "iter# = 44, ||X_new - X_old||_2 = 0.008696517726120734\n",
      "iter# = 45, ||X_new - X_old||_2 = 0.008457137335258382\n",
      "iter# = 46, ||X_new - X_old||_2 = 0.00826778467274078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 47, ||X_new - X_old||_2 = 0.00808730178820679\n",
      "iter# = 48, ||X_new - X_old||_2 = 0.007914221209145793\n",
      "iter# = 49, ||X_new - X_old||_2 = 0.007747669626169205\n",
      "iter# = 50, ||X_new - X_old||_2 = 0.007587141137736246\n",
      "iter# = 51, ||X_new - X_old||_2 = 0.007432254046709681\n",
      "iter# = 52, ||X_new - X_old||_2 = 0.007282686054866704\n",
      "iter# = 53, ||X_new - X_old||_2 = 0.00713815020893194\n",
      "iter# = 54, ||X_new - X_old||_2 = 0.006998386213439131\n",
      "iter# = 55, ||X_new - X_old||_2 = 0.00684184235947157\n",
      "iter# = 56, ||X_new - X_old||_2 = 0.006703406416645965\n",
      "iter# = 57, ||X_new - X_old||_2 = 0.006584086468839566\n",
      "iter# = 58, ||X_new - X_old||_2 = 0.006463230223258741\n",
      "iter# = 59, ||X_new - X_old||_2 = 0.006346437363376006\n",
      "iter# = 60, ||X_new - X_old||_2 = 0.006233323032880717\n",
      "iter# = 61, ||X_new - X_old||_2 = 0.006123672293482605\n",
      "iter# = 62, ||X_new - X_old||_2 = 0.006017311125701189\n",
      "iter# = 63, ||X_new - X_old||_2 = 0.00591408803863126\n",
      "iter# = 64, ||X_new - X_old||_2 = 0.005813866599611752\n",
      "iter# = 65, ||X_new - X_old||_2 = 0.005716521965056968\n",
      "iter# = 66, ||X_new - X_old||_2 = 0.005621939169476864\n",
      "iter# = 67, ||X_new - X_old||_2 = 0.005526642276956029\n",
      "iter# = 68, ||X_new - X_old||_2 = 0.00542774605137474\n",
      "iter# = 69, ||X_new - X_old||_2 = 0.005336784377492641\n",
      "iter# = 70, ||X_new - X_old||_2 = 0.005257580798397302\n",
      "iter# = 71, ||X_new - X_old||_2 = 0.005176018609646045\n",
      "iter# = 72, ||X_new - X_old||_2 = 0.005096742369370363\n",
      "iter# = 73, ||X_new - X_old||_2 = 0.005019548493287955\n",
      "iter# = 74, ||X_new - X_old||_2 = 0.004944337987219691\n",
      "iter# = 75, ||X_new - X_old||_2 = 0.00487102733921724\n",
      "iter# = 76, ||X_new - X_old||_2 = 0.004799541892994207\n",
      "iter# = 77, ||X_new - X_old||_2 = 0.004729812924735832\n",
      "iter# = 78, ||X_new - X_old||_2 = 0.004661776227269487\n",
      "iter# = 79, ||X_new - X_old||_2 = 0.00459537131452317\n",
      "iter# = 80, ||X_new - X_old||_2 = 0.004530540919007094\n",
      "iter# = 81, ||X_new - X_old||_2 = 0.004467230642918217\n",
      "iter# = 82, ||X_new - X_old||_2 = 0.004405388697372856\n",
      "iter# = 83, ||X_new - X_old||_2 = 0.004344965696572593\n",
      "iter# = 84, ||X_new - X_old||_2 = 0.004285914489039312\n",
      "iter# = 85, ||X_new - X_old||_2 = 0.004228190015967379\n",
      "iter# = 86, ||X_new - X_old||_2 = 0.0041717491912025085\n",
      "iter# = 87, ||X_new - X_old||_2 = 0.004116550800137894\n",
      "iter# = 88, ||X_new - X_old||_2 = 0.004062555417214812\n",
      "iter# = 89, ||X_new - X_old||_2 = 0.00400972534403645\n",
      "iter# = 90, ||X_new - X_old||_2 = 0.003958024573864106\n",
      "iter# = 91, ||X_new - X_old||_2 = 0.0039074187949041895\n",
      "iter# = 92, ||X_new - X_old||_2 = 0.0038578754593129416\n",
      "iter# = 93, ||X_new - X_old||_2 = 0.00380936398057135\n",
      "iter# = 94, ||X_new - X_old||_2 = 0.00376185622522047\n",
      "iter# = 95, ||X_new - X_old||_2 = 0.0037153278348171564\n",
      "iter# = 96, ||X_new - X_old||_2 = 0.0036660232326513153\n",
      "iter# = 97, ||X_new - X_old||_2 = 0.003617211913163074\n",
      "iter# = 98, ||X_new - X_old||_2 = 0.0035713862369903095\n",
      "iter# = 99, ||X_new - X_old||_2 = 0.0035286597556560347\n",
      "iter# = 100, ||X_new - X_old||_2 = 0.0034870415580396685\n",
      "iter# = 101, ||X_new - X_old||_2 = 0.003446345861922737\n",
      "iter# = 102, ||X_new - X_old||_2 = 0.0034064962350257013\n",
      "iter# = 103, ||X_new - X_old||_2 = 0.0033674444712704474\n",
      "iter# = 104, ||X_new - X_old||_2 = 0.003329154323099622\n",
      "iter# = 105, ||X_new - X_old||_2 = 0.003291595535413865\n",
      "iter# = 106, ||X_new - X_old||_2 = 0.003254741130692867\n",
      "iter# = 107, ||X_new - X_old||_2 = 0.003218565948913457\n",
      "iter# = 108, ||X_new - X_old||_2 = 0.0031830457094481125\n",
      "iter# = 109, ||X_new - X_old||_2 = 0.0031481563230302623\n",
      "iter# = 110, ||X_new - X_old||_2 = 0.0031138736562431775\n",
      "iter# = 111, ||X_new - X_old||_2 = 0.0030783672703222553\n",
      "iter# = 112, ||X_new - X_old||_2 = 0.0030424080629855156\n",
      "iter# = 113, ||X_new - X_old||_2 = 0.003012119645297699\n",
      "iter# = 114, ||X_new - X_old||_2 = 0.002977080618614499\n",
      "iter# = 115, ||X_new - X_old||_2 = 0.002948476721008509\n",
      "iter# = 116, ||X_new - X_old||_2 = 0.0029180309437200885\n",
      "iter# = 117, ||X_new - X_old||_2 = 0.0028880933260859993\n",
      "iter# = 118, ||X_new - X_old||_2 = 0.0028586935845519956\n",
      "iter# = 119, ||X_new - X_old||_2 = 0.0028298120846784194\n",
      "iter# = 120, ||X_new - X_old||_2 = 0.0028014316241081767\n",
      "iter# = 121, ||X_new - X_old||_2 = 0.002773537122631007\n",
      "iter# = 122, ||X_new - X_old||_2 = 0.0027461149214099614\n",
      "iter# = 123, ||X_new - X_old||_2 = 0.0027191523776648793\n",
      "iter# = 124, ||X_new - X_old||_2 = 0.0026926376234983392\n",
      "iter# = 125, ||X_new - X_old||_2 = 0.0026665594144084795\n",
      "iter# = 126, ||X_new - X_old||_2 = 0.0026409070290319948\n",
      "iter# = 127, ||X_new - X_old||_2 = 0.0026156701994751582\n",
      "iter# = 128, ||X_new - X_old||_2 = 0.002590839060723586\n",
      "iter# = 129, ||X_new - X_old||_2 = 0.0025664041123953994\n",
      "iter# = 130, ||X_new - X_old||_2 = 0.0025423561887987813\n",
      "iter# = 131, ||X_new - X_old||_2 = 0.002518686434742397\n",
      "iter# = 132, ||X_new - X_old||_2 = 0.0024953862854656767\n",
      "iter# = 133, ||X_new - X_old||_2 = 0.0024724474495982094\n",
      "iter# = 134, ||X_new - X_old||_2 = 0.002449861894407849\n",
      "iter# = 135, ||X_new - X_old||_2 = 0.002427621832815748\n",
      "iter# = 136, ||X_new - X_old||_2 = 0.002405719711796747\n",
      "iter# = 137, ||X_new - X_old||_2 = 0.0023841482019084145\n",
      "iter# = 138, ||X_new - X_old||_2 = 0.00236290018773401\n",
      "iter# = 139, ||X_new - X_old||_2 = 0.0023419687590737893\n",
      "iter# = 140, ||X_new - X_old||_2 = 0.0023213472027958774\n",
      "iter# = 141, ||X_new - X_old||_2 = 0.002301028995199811\n",
      "iter# = 142, ||X_new - X_old||_2 = 0.0022810077948572888\n",
      "iter# = 143, ||X_new - X_old||_2 = 0.002261277435846398\n",
      "iter# = 144, ||X_new - X_old||_2 = 0.0022418319213003885\n",
      "iter# = 145, ||X_new - X_old||_2 = 0.0022226654172671496\n",
      "iter# = 146, ||X_new - X_old||_2 = 0.0022037722467787967\n",
      "iter# = 147, ||X_new - X_old||_2 = 0.002185146884123515\n",
      "iter# = 148, ||X_new - X_old||_2 = 0.00216678394926328\n",
      "iter# = 149, ||X_new - X_old||_2 = 0.0021486782023298996\n",
      "iter# = 150, ||X_new - X_old||_2 = 0.002130824538189279\n",
      "iter# = 151, ||X_new - X_old||_2 = 0.002113217980970819\n",
      "iter# = 152, ||X_new - X_old||_2 = 0.0020958536785317733\n",
      "iter# = 153, ||X_new - X_old||_2 = 0.0020787268967286674\n",
      "iter# = 154, ||X_new - X_old||_2 = 0.0020618330134459574\n",
      "iter# = 155, ||X_new - X_old||_2 = 0.002045167512187448\n",
      "iter# = 156, ||X_new - X_old||_2 = 0.002028725975092299\n",
      "iter# = 157, ||X_new - X_old||_2 = 0.002012504075091724\n",
      "iter# = 158, ||X_new - X_old||_2 = 0.0019964975669364018\n",
      "iter# = 159, ||X_new - X_old||_2 = 0.0019807022766011977\n",
      "iter# = 160, ||X_new - X_old||_2 = 0.001965114088621029\n",
      "iter# = 161, ||X_new - X_old||_2 = 0.001949728930991695\n",
      "iter# = 162, ||X_new - X_old||_2 = 0.0019345427585675185\n",
      "iter# = 163, ||X_new - X_old||_2 = 0.0019195515422780623\n",
      "iter# = 164, ||X_new - X_old||_2 = 0.0019047513059212177\n",
      "iter# = 165, ||X_new - X_old||_2 = 0.0018897404265620105\n",
      "iter# = 166, ||X_new - X_old||_2 = 0.0018741585381369932\n",
      "iter# = 167, ||X_new - X_old||_2 = 0.0018591617309134027\n",
      "iter# = 168, ||X_new - X_old||_2 = 0.0018450221466321613\n",
      "iter# = 169, ||X_new - X_old||_2 = 0.0018311530577472404\n",
      "iter# = 170, ||X_new - X_old||_2 = 0.001817490202602924\n",
      "iter# = 171, ||X_new - X_old||_2 = 0.001804014406281188\n",
      "iter# = 172, ||X_new - X_old||_2 = 0.0017907156510616714\n",
      "iter# = 173, ||X_new - X_old||_2 = 0.0017775872885649664\n",
      "iter# = 174, ||X_new - X_old||_2 = 0.001764624267787538\n",
      "iter# = 175, ||X_new - X_old||_2 = 0.0017518224071513327\n",
      "iter# = 176, ||X_new - X_old||_2 = 0.0017391780493833072\n",
      "iter# = 177, ||X_new - X_old||_2 = 0.0017266878811308206\n",
      "iter# = 178, ||X_new - X_old||_2 = 0.0017143488311832937\n",
      "iter# = 179, ||X_new - X_old||_2 = 0.001702158009307566\n",
      "iter# = 180, ||X_new - X_old||_2 = 0.0016901126674828356\n",
      "iter# = 181, ||X_new - X_old||_2 = 0.0016782101741757947\n",
      "iter# = 182, ||X_new - X_old||_2 = 0.0016664479965726336\n",
      "iter# = 183, ||X_new - X_old||_2 = 0.0016548236878250206\n",
      "iter# = 184, ||X_new - X_old||_2 = 0.0016433348776280726\n",
      "iter# = 185, ||X_new - X_old||_2 = 0.00163197926501474\n",
      "iter# = 186, ||X_new - X_old||_2 = 0.0016207546127093098\n",
      "iter# = 187, ||X_new - X_old||_2 = 0.0016096587425874181\n",
      "iter# = 188, ||X_new - X_old||_2 = 0.0015986895319318477\n",
      "iter# = 189, ||X_new - X_old||_2 = 0.0015878449103049572\n",
      "iter# = 190, ||X_new - X_old||_2 = 0.001577122856853847\n",
      "iter# = 191, ||X_new - X_old||_2 = 0.0015665213979794653\n",
      "iter# = 192, ||X_new - X_old||_2 = 0.0015560386052775152\n",
      "iter# = 193, ||X_new - X_old||_2 = 0.001545672593689149\n",
      "iter# = 194, ||X_new - X_old||_2 = 0.0015354215198505245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter# = 195, ||X_new - X_old||_2 = 0.0015252835805623281\n",
      "iter# = 196, ||X_new - X_old||_2 = 0.0015152570113984997\n",
      "iter# = 197, ||X_new - X_old||_2 = 0.0015053400854170159\n",
      "iter# = 198, ||X_new - X_old||_2 = 0.0014955311119470404\n",
      "iter# = 199, ||X_new - X_old||_2 = 0.0014858284354629292\n",
      "iter# = 200, ||X_new - X_old||_2 = 0.0014762304345233928\n",
      "iter# = 201, ||X_new - X_old||_2 = 0.0014667355207653224\n",
      "iter# = 202, ||X_new - X_old||_2 = 0.0014573421379459196\n",
      "iter# = 203, ||X_new - X_old||_2 = 0.0014480487610481884\n",
      "iter# = 204, ||X_new - X_old||_2 = 0.001438853895407749\n",
      "iter# = 205, ||X_new - X_old||_2 = 0.0014297560758919534\n",
      "iter# = 206, ||X_new - X_old||_2 = 0.0014207538661127484\n",
      "iter# = 207, ||X_new - X_old||_2 = 0.001411845857666644\n",
      "iter# = 208, ||X_new - X_old||_2 = 0.0014030306694103449\n",
      "iter# = 209, ||X_new - X_old||_2 = 0.001394306946758957\n",
      "iter# = 210, ||X_new - X_old||_2 = 0.0013856733610164583\n",
      "iter# = 211, ||X_new - X_old||_2 = 0.0013771286087244617\n",
      "iter# = 212, ||X_new - X_old||_2 = 0.0013686714110457256\n",
      "iter# = 213, ||X_new - X_old||_2 = 0.0013603005131481104\n",
      "iter# = 214, ||X_new - X_old||_2 = 0.0013520146836271992\n",
      "iter# = 215, ||X_new - X_old||_2 = 0.001343812713948928\n",
      "iter# = 216, ||X_new - X_old||_2 = 0.0013356934178978216\n",
      "iter# = 217, ||X_new - X_old||_2 = 0.0013276556310473208\n",
      "iter# = 218, ||X_new - X_old||_2 = 0.001319698210257504\n",
      "iter# = 219, ||X_new - X_old||_2 = 0.0013118200331712385\n",
      "iter# = 220, ||X_new - X_old||_2 = 0.001304019997738711\n",
      "iter# = 221, ||X_new - X_old||_2 = 0.0012962970217541734\n",
      "iter# = 222, ||X_new - X_old||_2 = 0.0012886500424010591\n",
      "iter# = 223, ||X_new - X_old||_2 = 0.0012810780158135932\n",
      "iter# = 224, ||X_new - X_old||_2 = 0.001273579916652341\n",
      "iter# = 225, ||X_new - X_old||_2 = 0.0012661547376927838\n",
      "iter# = 226, ||X_new - X_old||_2 = 0.0012588014894247656\n",
      "iter# = 227, ||X_new - X_old||_2 = 0.0012515191996566386\n",
      "iter# = 228, ||X_new - X_old||_2 = 0.001244306913143469\n",
      "iter# = 229, ||X_new - X_old||_2 = 0.001237163691212356\n",
      "iter# = 230, ||X_new - X_old||_2 = 0.0012300886114068384\n",
      "iter# = 231, ||X_new - X_old||_2 = 0.0012230807671404407\n",
      "iter# = 232, ||X_new - X_old||_2 = 0.0012161392673541791\n",
      "iter# = 233, ||X_new - X_old||_2 = 0.0012092632361815339\n",
      "iter# = 234, ||X_new - X_old||_2 = 0.0012024518126396283\n",
      "iter# = 235, ||X_new - X_old||_2 = 0.0011957041503050869\n",
      "iter# = 236, ||X_new - X_old||_2 = 0.0011890194170119269\n",
      "iter# = 237, ||X_new - X_old||_2 = 0.001182396794554916\n",
      "iter# = 238, ||X_new - X_old||_2 = 0.0011758354784011794\n",
      "iter# = 239, ||X_new - X_old||_2 = 0.001169334677408296\n",
      "iter# = 240, ||X_new - X_old||_2 = 0.0011628936135449346\n",
      "iter# = 241, ||X_new - X_old||_2 = 0.0011565115216300088\n",
      "iter# = 242, ||X_new - X_old||_2 = 0.0011501876490647679\n",
      "iter# = 243, ||X_new - X_old||_2 = 0.0011439212555790855\n",
      "iter# = 244, ||X_new - X_old||_2 = 0.001137711612988204\n",
      "iter# = 245, ||X_new - X_old||_2 = 0.0011315580049438164\n",
      "iter# = 246, ||X_new - X_old||_2 = 0.0011254597266999386\n",
      "iter# = 247, ||X_new - X_old||_2 = 0.0011194160848835171\n",
      "iter# = 248, ||X_new - X_old||_2 = 0.0011134263972637885\n",
      "iter# = 249, ||X_new - X_old||_2 = 0.001107489992543017\n",
      "iter# = 250, ||X_new - X_old||_2 = 0.0011016062101272092\n",
      "iter# = 251, ||X_new - X_old||_2 = 0.0010957743999291238\n",
      "iter# = 252, ||X_new - X_old||_2 = 0.0010899939221574772\n",
      "iter# = 253, ||X_new - X_old||_2 = 0.0010842641471162718\n",
      "iter# = 254, ||X_new - X_old||_2 = 0.001078584455014611\n",
      "iter# = 255, ||X_new - X_old||_2 = 0.0010729542357734367\n",
      "iter# = 256, ||X_new - X_old||_2 = 0.0010673728888331855\n",
      "iter# = 257, ||X_new - X_old||_2 = 0.0010618398229816286\n",
      "iter# = 258, ||X_new - X_old||_2 = 0.0010563544561708236\n",
      "iter# = 259, ||X_new - X_old||_2 = 0.0010509162153456652\n",
      "iter# = 260, ||X_new - X_old||_2 = 0.0010455245362661165\n",
      "iter# = 261, ||X_new - X_old||_2 = 0.0010401788633553764\n",
      "iter# = 262, ||X_new - X_old||_2 = 0.0010348786495238413\n",
      "iter# = 263, ||X_new - X_old||_2 = 0.0010296233560185381\n",
      "iter# = 264, ||X_new - X_old||_2 = 0.0010244124522649032\n",
      "iter# = 265, ||X_new - X_old||_2 = 0.001019245415713083\n",
      "iter# = 266, ||X_new - X_old||_2 = 0.001014121731697551\n",
      "iter# = 267, ||X_new - X_old||_2 = 0.00100904089328094\n",
      "iter# = 268, ||X_new - X_old||_2 = 0.0010040024011196565\n",
      "Number of steps: 270\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Run algorithm\n",
    "epsilon = 1e-3                # Precision parameter\n",
    "iters = 1000\n",
    "eta = 0.1\n",
    "\n",
    "U, S, V = la.svd(X_star)\n",
    "l = np.sum(S)\n",
    "\n",
    "X_IHT, X_list_IHT, f_list_IHT = matrix_IHT(y, A, r, eta, iters, epsilon, True, X_star)\n",
    "X_NN, X_list_NN, f_list_NN = matrix_nuclear_norm_min(y, A, l, eta, iters, epsilon, True, X_star)\n",
    "\n",
    "# Plot\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "\n",
    "xs_IHT = range(len(X_list_IHT))\n",
    "xs_NN = range(len(X_list_NN))\n",
    "\n",
    "plt.plot(xs_IHT, X_list_IHT, '-o', color = '#3399FF', linewidth = 2, alpha = 0.7) # Blue\n",
    "plt.plot(xs_NN, X_list_NN, '-o', color = '#FF6666', linewidth = 2, alpha = 0.7) # Red\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel(r\"$\\|x^\\star - \\widehat{x}\\|_2$\")\n",
    "\n",
    "# Make room for the ridiculously large title.\n",
    "plt.subplots_adjust(top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
